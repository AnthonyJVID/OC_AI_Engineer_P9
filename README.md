# ğŸš— Preuve de Concept â€“ SegFormer pour la Segmentation dâ€™Images Urbaines

Ce projet est rÃ©alisÃ© dans le cadre du parcours AI Engineer dâ€™OpenClassrooms

Le dÃ©pÃ´t prÃ©sente une **preuve de concept (PoC)** dans le cadre dâ€™un test technique pour lâ€™entreprise **DataSpace**, visant Ã  dÃ©montrer la supÃ©rioritÃ© dâ€™un modÃ¨le de segmentation dâ€™images rÃ©cent, **SegFormer B5**, face Ã  une baseline classique **U-Net (EfficientNetB3)**.

---

## ğŸ¯ Objectif

- **ProblÃ©matique mÃ©tier :** AmÃ©liorer les performances de la segmentation dâ€™images embarquÃ©es dans des vÃ©hicules autonomes.
- **DÃ©fi technique :** Mettre en Å“uvre une mÃ©thode rÃ©cente (moins de 5 ans) issue de la veille technologique, pour amÃ©liorer vitesse, prÃ©cision et efficacitÃ© mÃ©moire.
- **ModÃ¨le Ã©valuÃ© :** SegFormer B5 (architecture Transformer) vs U-Net + EfficientNetB3.

---

## ğŸ—‚ Structure du dÃ©pÃ´t

```
â”œâ”€â”€ notebook.ipynb              â† Comparaison des modÃ¨les (baseline vs SegFormer)
â”œâ”€â”€ fonctions.py                â† Fonctions utilitaires : preprocessing, mÃ©triques, affichage
â”œâ”€â”€ code_dashboard.py           â† Application Streamlit interactive de comparaison
â”œâ”€â”€ note_methodo.pdf            â† Note mÃ©thodologique avec rÃ©sultats et analyse
â”œâ”€â”€ plan_travail.pdf            â† Plan prÃ©visionnel validÃ© pour la PoC
```

---

## ğŸ“š DonnÃ©es

- **Dataset utilisÃ© :** [Cityscapes](https://www.cityscapes-dataset.com/)
- **Images utilisÃ©es :** 2000 (train), 500 (validation)
- **Dimensions :** 256x256 px
- **Classes :** 8 grandes catÃ©gories remappÃ©es Ã  partir des 34 originales

---

## ğŸ§  ModÃ¨les comparÃ©s

| ModÃ¨le           | Framework    | Type             | DÃ©ploiement Cloud            |
|------------------|--------------|------------------|------------------------------|
| EfficientNetB3   | Keras        | CNN              | **AWS EC2 (FastAPI)**        |
| SegFormer B5     | PyTorch      | Transformer      | **Hugging Face Space**       |

---

## ğŸ§ª Ã‰valuation

- **MÃ©triques** : `Accuracy`, `Dice`, `mIoU`, `Loss`, `Temps d'entraÃ®nement`
- **Outils** :
  - EntraÃ®nement avec **Albumentations**, `torch.cuda.amp` (mixed precision), `ReduceLROnPlateau`
  - Visualisation des performances par epoch
  - Comparaison via **Streamlit dashboard**
  - Appels API vers modÃ¨les dÃ©ployÃ©s sur le cloud

---

## ğŸ“Š RÃ©sultats

| ModÃ¨le        | Accuracy | Dice | mIoU | Loss  | Temps entraÃ®nement |
|---------------|----------|------|------|-------|---------------------|
| SegFormer B5  | ~0.90    | 0.83 | 0.70 | ~0.20 | **160.93 min**      |
| U-Net (EffB3) | ~0.91    | 0.86 | 0.67 | ~0.45 | 368.37 min          |

- **SegFormer** offre une **meilleure gÃ©nÃ©ralisation** (mIoU) et un **temps d'entraÃ®nement bien plus court**
- **U-Net** reste lÃ©gÃ¨rement supÃ©rieur en Dice, mais plus coÃ»teux en calcul

---

## ğŸ–¥ï¸ Dashboard interactif

Le fichier `code_dashboard.py` fournit une interface **Streamlit** permettant de :

- Comparer les masques rÃ©els et prÃ©dits pour chaque modÃ¨le
- Obtenir les mÃ©triques associÃ©es (Dice, IoU)
- Consommer dynamiquement les **API de prÃ©diction** :
  - **SegFormer dÃ©ployÃ© sur Hugging Face**
  - **EfficientNetB3 dÃ©ployÃ© sur AWS EC2 (FastAPI)**

---

## ğŸ“„ Documentation

- `note_methodo.pdf` : Analyse dÃ©taillÃ©e des rÃ©sultats, fonctionnement du modÃ¨le SegFormer, comprÃ©hension des concepts
- `plan_travail.pdf` : Justification du modÃ¨le choisi, rÃ©fÃ©rences bibliographiques, mÃ©thode de test

---

## ğŸ” RÃ©fÃ©rences

- [SegFormer â€“ Article Arxiv](https://arxiv.org/abs/2105.15203)
- [Blog Medium â€“ SegFormer](https://medium.com/geekculture/semantic-segmentation-with-segformer-2501543d2be4)
- [Tutoriel Debugger CafÃ©](https://debuggercafe.com/segformer-for-semantic-segmentation)

---

## ğŸ‘¨â€ğŸ’» Auteur

Projet rÃ©alisÃ© par **AnthonyJVID** dans le cadre de la mission 9 â€“ Preuve de concept IA pour DataSpace.
